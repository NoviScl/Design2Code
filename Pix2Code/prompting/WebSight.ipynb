{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0260f9d-dfb6-41a4-aff7-843bb54a9423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1243b9751d314886ad4b8f7c91765d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "from transformers.image_utils import to_numpy_array, PILImageResampling, ChannelDimension\n",
    "from transformers.image_transforms import resize, to_channel_dimension_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebee5375-f4a2-4f1f-8cf1-a0b4989c5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "HF_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f06705c-c85b-4faa-9d25-771a005c1be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb980f11fb64e8f876b5fdb2f2c9b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/351 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23e7c5fece54d7e80a1dfab6c7d6df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05da24d2631b4eea92ab6bdf6e1e457f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26fc5e288e26415f893fadb205663dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d421c33155447a9a92074ae31b562ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23867e2a063f4414ae5707cd9bc6b418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/552 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93842bc205b849a38be8186e33cb1501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114d95e9e3844973b6a60c599b9eb9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)guration_vmistral.py:   0%|          | 0.00/14.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/HuggingFaceM4/VLM_WebSight_finetuned:\n",
      "- configuration_vmistral.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325fe078d6c41f1935afca2e625bb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modeling_vmistral.py:   0%|          | 0.00/81.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/HuggingFaceM4/VLM_WebSight_finetuned:\n",
      "- modeling_vmistral.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab53f224684749f2ab1b8b41744da9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/79.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3c5dc2f29f478680078a3e51fccf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acae85204fa456fad08e6ee777707cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e2a80eeb8d4f96b2b01fd523442e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b41ea97d574ecfb1cb0e3985d9adc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522ed2a292444bbfaac36b375a097a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00004.safetensors:   0%|          | 0.00/1.69G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf75b06d2bc4b8ba0f5c1f480badb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/clsi/miniconda3/envs/pix2code/lib/python3.11/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b6ce7dc5b44f14804caee6d0e2525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROCESSOR = AutoProcessor.from_pretrained(\n",
    "    \"HuggingFaceM4/VLM_WebSight_finetuned\",\n",
    "    token=HF_TOKEN,\n",
    "    cache_dir=\"/juice2/scr2/nlp/pix2code/huggingface\"\n",
    ")\n",
    "MODEL = AutoModelForCausalLM.from_pretrained(\n",
    "    \"HuggingFaceM4/VLM_WebSight_finetuned\",\n",
    "    token=HF_TOKEN,\n",
    "    cache_dir=\"/juice2/scr2/nlp/pix2code/huggingface\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d017466-5fb2-4e04-9477-e0db17caeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_seq_len = MODEL.config.perceiver_config.resampler_n_latents\n",
    "BOS_TOKEN = PROCESSOR.tokenizer.bos_token\n",
    "BAD_WORDS_IDS = PROCESSOR.tokenizer([\"<image>\", \"<fake_token_around_image>\"], add_special_tokens=False).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c54dba-a5a2-4831-9a37-41cfe4b8eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_rgb(image):\n",
    "    # `image.convert(\"RGB\")` would only work for .jpg images, as it creates a wrong background\n",
    "    # for transparent images. The call to `alpha_composite` handles this case\n",
    "    if image.mode == \"RGB\":\n",
    "        return image\n",
    "\n",
    "    image_rgba = image.convert(\"RGBA\")\n",
    "    background = Image.new(\"RGBA\", image_rgba.size, (255, 255, 255))\n",
    "    alpha_composite = Image.alpha_composite(background, image_rgba)\n",
    "    alpha_composite = alpha_composite.convert(\"RGB\")\n",
    "    return alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d82121-1382-46ff-b4a4-b55f47555c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The processor is the same as the Idefics processor except for the BILINEAR interpolation,\n",
    "# so this is a hack in order to redefine ONLY the transform method\n",
    "def custom_transform(x):\n",
    "    x = convert_to_rgb(x)\n",
    "    x = to_numpy_array(x)\n",
    "    x = resize(x, (960, 960), resample=PILImageResampling.BILINEAR)\n",
    "    x = PROCESSOR.image_processor.rescale(x, scale=1 / 255)\n",
    "    x = PROCESSOR.image_processor.normalize(\n",
    "        x,\n",
    "        mean=PROCESSOR.image_processor.image_mean,\n",
    "        std=PROCESSOR.image_processor.image_std\n",
    "    )\n",
    "    x = to_channel_dimension_format(x, ChannelDimension.FIRST)\n",
    "    x = torch.tensor(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545cbe8e-31ff-4542-8725-9b9a451708ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = PROCESSOR.tokenizer(\n",
    "    f\"{BOS_TOKEN}<fake_token_around_image>{'<image>' * image_seq_len}<fake_token_around_image>\",\n",
    "    return_tensors=\"pt\",\n",
    "    add_special_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607fc19c-bf14-40b0-a01c-6001eabf0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../../testset_100/5672.png'\n",
    "with Image.open(image_path) as image:\n",
    "    inputs[\"pixel_values\"] = PROCESSOR.image_processor([image], transform=custom_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e31f48-cca5-40e1-ac22-4598b5622426",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "generated_ids = MODEL.generate(**inputs, bad_words_ids=BAD_WORDS_IDS, max_length=4096)\n",
    "generated_text = PROCESSOR.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5974a068-21cd-4f08-9c2b-72e0200e8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<style>\n",
      "* {\n",
      "    margin: 0;\n",
      "    padding: 0;\n",
      "    box-sizing: border-box;\n",
      "}\n",
      "\n",
      "body {\n",
      "    font-family: 'Playfair Display', serif;\n",
      "    color: #333;\n",
      "}\n",
      "\n",
      "header {\n",
      "    position: fixed;\n",
      "    top: 0;\n",
      "    left: 0;\n",
      "    width: 100%;\n",
      "    display: flex;\n",
      "    justify-content: space-between;\n",
      "    align-items: center;\n",
      "    padding: 1rem 2rem;\n",
      "    background-color: #fff;\n",
      "    box-shadow: 0 2px 5px rgba(0, 0, 0, 0.3);\n",
      "}\n",
      "\n",
      ".logo {\n",
      "    font-size: 1.5rem;\n",
      "    color: #575fcf;\n",
      "}\n",
      "\n",
      "nav ul {\n",
      "    display: flex;\n",
      "    list-style: none;\n",
      "}\n",
      "\n",
      "nav ul li {\n",
      "    margin: 0 1rem;\n",
      "}\n",
      "\n",
      "nav ul li a {\n",
      "    text-decoration: none;\n",
      "    color: #575fcf;\n",
      "    font-size: 1.2rem;\n",
      "}\n",
      "\n",
      ".cta {\n",
      "    background-color: #575fcf;\n",
      "    color: #fff;\n",
      "    padding: 1rem 2rem;\n",
      "    text-transform: uppercase;\n",
      "    letter-spacing: 0.1rem;\n",
      "}\n",
      "\n",
      ".hero {\n",
      "    height: 100vh;\n",
      "    display: flex;\n",
      "    flex-direction: column;\n",
      "    justify-content: center;\n",
      "    align-items: center;\n",
      "    text-align: center;\n",
      "    padding: 2rem;\n",
      "}\n",
      "\n",
      ".hero h1 {\n",
      "    font-size: 4rem;\n",
      "    margin-bottom: 1rem;\n",
      "    color: #575fcf;\n",
      "}\n",
      "\n",
      ".hero p {\n",
      "    font-size: 1.2rem;\n",
      "    margin-bottom: 2rem;\n",
      "}\n",
      "\n",
      ".hero button {\n",
      "    background-color: #575fcf;\n",
      "    color: #fff;\n",
      "    padding: 1rem 2rem;\n",
      "    text-transform: uppercase;\n",
      "    letter-spacing: 0.1rem;\n",
      "}\n",
      "\n",
      ".image-placeholder {\n",
      "    width: 80%;\n",
      "    height: 200px;\n",
      "    background-color: #00f;\n",
      "    margin: 2rem 0;\n",
      "}\n",
      "\n",
      ".user-content {\n",
      "    position: fixed;\n",
      "    bottom: 0;\n",
      "    left: 0;\n",
      "    width: 100%;\n",
      "    padding: 1rem;\n",
      "    background-color: #fff;\n",
      "    box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.3);\n",
      "}\n",
      "\n",
      ".user-content p {\n",
      "    font-size: 0.9rem;\n",
      "    margin-bottom: 1rem;\n",
      "}\n",
      "\n",
      ".user-content a {\n",
      "    text-decoration: none;\n",
      "    color: #575fcf;\n",
      "    font-size: 0.9rem;\n",
      "}\n",
      "</style>\n",
      "<body>\n",
      "    <header>\n",
      "        <div class=\"logo\">Tidy Cleaning Solutions</div>\n",
      "        <nav>\n",
      "            <ul>\n",
      "                <li><a href=\"#\">Home</a></li>\n",
      "                <li><a href=\"#\">About</a></li>\n",
      "                <li><a href=\"#\">Services</a></li>\n",
      "                <li><a href=\"#\">Contact</a></li>\n",
      "            </ul>\n",
      "        </nav>\n",
      "        <a href=\"#\" class=\"cta\">Call Now</a>\n",
      "    </header>\n",
      "    <section class=\"hero\">\n",
      "        <h1>Tidy Cleaning Solutions</h1>\n",
      "        <p>Commercial Cleaning Service<br>Open 24 hours</p>\n",
      "        <button>Get Quote</button>\n",
      "        <div class=\"image-placeholder\"></div>\n",
      "    </section>\n",
      "    <section class=\"user-content\">\n",
      "        <p>This site uses cookies from Google.</p>\n",
      "        <a href=\"#\">Learn more</a>\n",
      "    </section>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db6bb74-803f-4b5e-a1b9-26b3fa0aae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7b40f9a-f638-4e33-81a5-00a8de147f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 201/201 [32:46<00:00,  9.78s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data_dir = \"../../testset_100\"\n",
    "predictions_dir = \"../../predictions_100/websight\"\n",
    "\n",
    "for filename in tqdm(os.listdir(test_data_dir)):\n",
    "    if filename.endswith(\"2.png\") or filename.endswith(\"5.png\"):\n",
    "        image_path = os.path.join(test_data_dir, filename)\n",
    "        with Image.open(image_path) as image:\n",
    "            inputs[\"pixel_values\"] = PROCESSOR.image_processor([image], transform=custom_transform)\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        generated_ids = MODEL.generate(**inputs, bad_words_ids=BAD_WORDS_IDS, max_length=4096)\n",
    "        generated_text = PROCESSOR.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        with open(os.path.join(predictions_dir, filename.replace(\".png\", \".html\")), \"w\", encoding='utf-8') as f:\n",
    "            f.write(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a2ed8-ae8f-4116-9009-8a064bda0294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
